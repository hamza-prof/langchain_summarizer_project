  name: "ğŸ§  LangChain Text Summarizer"
  description: >
    ğŸ“ A modular and customizable text summarization and retrieval project powered by LangChain. 
    Includes an intelligent agent that chooses between LLM-based summarization or 
    RAG (Retrieval-Augmented Generation) depending on user input.

  features:
    - ğŸ“„ Load and read plain text documents
    - âœ‚ï¸ Split long documents into overlapping chunks
    - ğŸ§  Summarize using customizable LLM prompt templates
    - ğŸ” Retrieve document answers using vector search (RAG)
    - ğŸ¤– Intelligent agent chooses between summarizer and retriever
    - âš™ï¸ Modular architecture for easy extension
    - ğŸ” API key and logging support via `.env` and `helpers.py`

  structure:
    root:
      - main.py: ğŸš€ Entry point script
      - requirements.txt: ğŸ“¦ Python dependencies
      - .env: ğŸ” API keys and secrets
    folders:
      - config:
          - prompts.py: âœï¸ Prompt templates and agent system prompt
      - data:
          - sample.txt: ğŸ§ª Example input text
      - modules:
          - loader.py: ğŸ“‚ Loads and chunks text
          - summarizer.py: ğŸ§  Summarization logic
          - retriever.py: ğŸ” RAG retriever
          - agent.py: ğŸ¤– Agent logic and tool registration
      - outputs:
          - summary.txt: ğŸ“ Summarized output
      - utils:
          - helpers.py: ğŸ”§ Text chunking, logging, env loader

  setup:
    - ğŸ› ï¸ Clone repository:
        command: git clone https://github.com/your-username/langchain_summarizer_project.git
    - ğŸ“ Navigate into project:
        command: cd langchain_summarizer_project
    - ğŸ§ª Create virtual environment:
        command: python -m venv venv
    - âš¡ Activate environment (Windows):
        command: .\venv\Scripts\activate
    - ğŸ“¦ Install dependencies:
        command: pip install -r requirements.txt
    - ğŸ” Create `.env` file:
        content: |
          OPENAI_API_KEY=your_openai_api_key
          HUGGINGFACEHUB_API_TOKEN=your_huggingface_token

  usage:
    - ğŸ”ƒ Run full pipeline:
        command: python main.py
    - ğŸ§© Run loader:
        command: python -m modules.loader
    - ğŸ§  Run summarizer:
        command: python -m modules.summarizer
    - ğŸ¤– Run agent decision logic:
        command: python -m modules.agent

  output:
    file: outputs/summary.txt
    format: ğŸ“‹ Bullet-point summary with key ideas preserved

  customization:
    - âœï¸ Prompt templates: config/prompts.py
    - âœ‚ï¸ Chunking strategy: modules/loader.py
    - ğŸ§  LLM summarizer logic: modules/summarizer.py
    - ğŸ” RAG retriever logic: modules/retriever.py
    - ğŸ¤– Agent controller: modules/agent.py

  tools:
    - name: ğŸ§  summarize_text
      type: LangChain Tool
      source: modules/summarizer.py
      description: Summarizes long text into concise bullet points
    - name: ğŸ” retrieve_answer
      type: LangChain Tool
      source: modules/retriever.py
      description: Answers document questions using vector DB (RAG)

  agent:
    file: modules/agent.py
    description: >
      ğŸ¤– A LangChain-powered agent that decides whether to summarize or retrieve answers 
      based on the userâ€™s intent. Selects tools using OpenAI Function Calling.
    system_prompt: |
      You are an intelligent assistant.

      If the user's input is long and needs simplification, use the summarizer tool.
      If the user asks a question that might require document retrieval, use the retriever tool.

      Decide wisely. Return only relevant and clear information.
    examples:
      - query: "Please summarize this transcript."
        tool_used: ğŸ§  summarize_text
      - query: "What did the report say about the budget?"
        tool_used: ğŸ” retrieve_answer

  author:
    name: "ğŸ‘¨â€ğŸ’» Muhammad Hamza"
    github: https://github.com/hamza-prof
    license: MIT
